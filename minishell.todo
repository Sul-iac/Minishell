// telecharger l'extension To Do Task de Sandeep Somavarapu

// ctrl + enter pour ajoputer une task
// alt + d pour valider la tache

☐ faire notre propre fonction getline
☐ gestion d'erreurs:
    ☐ redirection vers une fonction free
    ☐ indiquer l'erreur avec perror
☐ lexer:
    ✔ creer le tableau de recherche @done (8/21/2024, 9:40:34 PM)
    ✔ cd : on va devoir trouver un moyen de transformer le chemin r/a en token, avec getcwd() ? @done (8/23/2024, 11:43:25 AM)
    ✔ echo ou tout autre commande necessitant un argument ou des options. Comment faire pour tokeniser ca ? @done (8/23/2024, 11:43:23 AM)
    ✔ fonctions de creation de token @done (8/24/2024, 6:53:25 PM)
    ✔ fonction de separations @done (8/24/2024, 6:53:52 PM)
	☐ fonction de tokenisation d'arguments
	
☐ parseur
    ☐ envoie des commandes/options/arguments


dans le lexeur:
	la variable count_token dans le code me permet juste de tester et d'afficher les tokens dans l'output.

PROBLEMES: 
	je n'ai alloue de la memoire que pour 100 tokens. A voir si dans les tests de corrections
	ils y a des tests avec des commandes extremement longues, ce que je pense etre le cas. Dans ce
	cas, il y a deux options, soit allouer plus de place dans le tableau, soit faire un tableau
	dynamique, donc en liste chainees, ce qui risque d'etre mega chiant, mais au moins les test passeront.
